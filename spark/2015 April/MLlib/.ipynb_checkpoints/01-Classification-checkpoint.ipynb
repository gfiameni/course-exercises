{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Predict survival on the Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'1.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_PATH = \"file:///notebooks/cineca/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp_file = sc.textFile(FILE_PATH + \"titanic/titanic3_01.csv\")\n",
    "pass_rdd = inp_file.map(lambda line: line.split(','))\n",
    "# 0 pclass,1 survived,2 l.name,3.f.name, 4 sex,5 age,6 sibsp,7 parch,8 ticket,9 fare,10 cabin,\n",
    "# 11 embarked,12 boat,13 body,14 home.dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>l.name</th>\n",
       "      <th>f.name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Allen</td>\n",
       "      <td>Miss. Elisabeth Walton\"</td>\n",
       "      <td>female</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>\"St Louis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Allison</td>\n",
       "      <td>Master. Hudson Trevor\"</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>\"Montreal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Allison</td>\n",
       "      <td>Miss. Helen Loraine\"</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\"Montreal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pclass survived    l.name                    f.name     sex     age sibsp  \\\n",
       "0      1        1    \"Allen   Miss. Elisabeth Walton\"  female      29     0   \n",
       "1      1        1  \"Allison    Master. Hudson Trevor\"    male  0.9167     1   \n",
       "2      1        0  \"Allison      Miss. Helen Loraine\"  female       2     1   \n",
       "\n",
       "  parch  ticket      fare    cabin embarked boat body  home.dest  \n",
       "0     0   24160  211.3375       B5        S    2       \"St Louis  \n",
       "1     2  113781  151.5500  C22 C26        S   11       \"Montreal  \n",
       "2     2  113781  151.5500  C22 C26        S            \"Montreal  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cols = [\"pclass\",\"survived\",\"l.name\",\"f.name\", \"sex\", \"age\", \"sibsp\",\"parch\",\"ticket\", \"fare\",\"cabin\",\"embarked\",\"boat\",\"body\",\"home.dest\"]\n",
    "data = pd.DataFrame(pass_rdd.take(3))\n",
    "data = data.ix[:,0:14]\n",
    "data.columns = cols\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###LabeledPoint\n",
    "LabeledPoint: The features and labels of a data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "def num(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return float(s)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "\n",
    "def parse_passenger_list(x):\n",
    "    pclass = num(x[0])\n",
    "    survived = num(x[1])\n",
    "    # sex\n",
    "    sex=0\n",
    "    if x[4]=='male':\n",
    "        sex = 1\n",
    "    age=0\n",
    "    age = num(x[5])\n",
    "    sibsp = 0\n",
    "    sibsp = num(x[6])\n",
    "    parch = 0\n",
    "    parch = num(x[7])\n",
    "    fare = 0\n",
    "    fare = num(x[9])\n",
    "    cabin = x[10] # not now, categorical\n",
    "    # return labelled point\n",
    "    return LabeledPoint(survived,[pclass,sex,age,sibsp,parch,fare]) #,cabin])\n",
    "    #[pclass,sex,age,sibsp,parch,fare,cabin,survived]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pass_rdd_01 = pass_rdd.map(lambda x: parse_passenger_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1310"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_rdd_01.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(1.0, [1.0,0.0,29.0,0.0,0.0,211.3375])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_rdd_01.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived,[pclass,sex,age,sibsp,parch,fare]\n",
      "(1.0,[1.0,0.0,29.0,0.0,0.0,211.3375])\n",
      "(1.0,[1.0,1.0,0.9167,1.0,2.0,151.55])\n",
      "(0.0,[1.0,0.0,2.0,1.0,2.0,151.55])\n"
     ]
    }
   ],
   "source": [
    "print \"survived,[pclass,sex,age,sibsp,parch,fare]\"\n",
    "for x in pass_rdd_01.take(3):\n",
    "    print x\n",
    "# survived,[pclass,sex,age,sibsp,parch,fare]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Decision trees\n",
    "Decision trees and their ensembles are popular methods for the machine learning tasks of classification and regression. Decision trees are widely used since they are easy to interpret, handle categorical features, extend to the multiclass classification setting, do not require feature scaling, and are able to capture non-linearities and feature interactions. Tree ensemble algorithms such as random forests and boosting are among the top performers for classification and regression tasks.\n",
    "\n",
    "MLlib supports decision trees for binary and multiclass classification and for regression, using both continuous and categorical features. The implementation partitions data by rows, allowing distributed training with millions of instances.\n",
    "\n",
    "[Documentation mllib#decisiontree](https://spark.apache.org/docs/latest/mllib-decision-tree.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree\n",
    "\n",
    "# numClasses: Number of classes (for Classification only)\n",
    "model = DecisionTree.trainClassifier(pass_rdd_01, numClasses=2,categoricalFeaturesInfo={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeModel classifier of depth 5 with 61 nodes\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "#print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pass_labels = pass_rdd_01.map(lambda x: x.label)\n",
    "\n",
    "pass_features = pass_rdd_01.map(lambda x: x.features)\n",
    "pass_features_array = pass_rdd_01.map(lambda x: [x.features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1310"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_labels.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for x in pass_labels.take(3):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(pass_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for x in predictions.take(3):\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelsAndPredictions = pass_rdd_01.map(lambda lp: lp.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 1.0),\n",
       " (1.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (0.0, 1.0),\n",
       " (1.0, 0.0),\n",
       " (1.0, 1.0),\n",
       " (0.0, 0.0),\n",
       " (1.0, 1.0),\n",
       " (0.0, 0.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labelsAndPredictions.first()\n",
    "labelsAndPredictions.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainMSE = labelsAndPredictions.map(lambda (v, p): (v - p)**2).sum() / float(pass_rdd_01.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.173282442748\n"
     ]
    }
   ],
   "source": [
    "print trainMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 82.67%\n"
     ]
    }
   ],
   "source": [
    "add = (lambda x,y : x+y)\n",
    "seqOp = (lambda acc, x: acc + (x[0] == x[1]))\n",
    "train_correct = labelsAndPredictions.aggregate(0, seqOp, add)\n",
    "accuracy = train_correct / float(pass_rdd_01.count())\n",
    "print 'accuracy: %2.2f%s' % (accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Let us try Naive Bayes & See if it improves the accuracy\n",
    "####Naive Bayes\n",
    "Naive Bayes is a simple multiclass classification algorithm with the assumption of independence between every pair of features. Naive Bayes can be trained very efficiently. Within a single pass to the training data, it computes the conditional probability distribution of each feature given label, and then it applies Bayes’ theorem to compute the conditional probability distribution of label given an observation and use it for prediction.\n",
    "\n",
    "MLlib supports multinomial naive Bayes, which is typically used for document classification. Within that context, each observation is a document and each feature represents a term whose value is the frequency of the term. Feature values must be nonnegative to represent term frequencies. Additive smoothing can be used by setting the parameter λ (default to 1.0). For document classification, the input feature vectors are usually sparse, and sparse vectors should be supplied as input to take advantage of sparsity. Since the training data is only used once, it is not necessary to cache it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.mllib.classification.NaiveBayesModel object at 0x7fc2ac0c0ad0>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes\n",
    "nb_model = NaiveBayes.train(pass_rdd_01, 1.0)\n",
    "print nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_predictions = pass_features_array.map(lambda x: nb_model.predict(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pass_features_array\n",
    "#aa = pass_features_array.take(1)\n",
    "#aa[0][0]\n",
    "#a = aa[0]\n",
    "#a = aa[0].tolist()\n",
    "#nb_model.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nb_predictions.first()\n",
    "nb_predictions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelsAndPredictions_nb = pass_rdd_01.map(lambda lp: lp.label).zip(nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsAndPredictions_nb.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.331297709924\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "trainMSE_nb = labelsAndPredictions_nb.map(lambda (l, p): numpy.square(l - p)).sum() / float(pass_rdd_01.count())\n",
    "print trainMSE_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 66.87%\n"
     ]
    }
   ],
   "source": [
    "seqOp = (lambda acc, x: acc + (x[0] == x[1]))\n",
    "train_correct = labelsAndPredictions_nb.aggregate(0, seqOp, add)\n",
    "accuracy = train_correct / float(pass_rdd_01.count())\n",
    "print 'accuracy: %2.2f%s' % (accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Homework\n",
    "# https://github.com/apache/spark/blob/master/examples/src/main/python/mllib/decision_tree_runner.py\n",
    "# has some interesting (and elegant) routines we can use"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Actually we would split train & test dataset & experiment with different features\n",
    "# Leave it as a Homework Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
