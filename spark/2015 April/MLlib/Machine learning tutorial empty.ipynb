{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Machine learning tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will realize a script for a raccomandation system on movie based on your personal rating and a dataset of 1 million ratings from 6000 users on 4000 movies.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Dataset\n",
    "\n",
    "We will use two files from MovieLens dataset: ratings.dat and movies.dat.  \n",
    "\n",
    "ratings.dat is in the fellowing format:  \n",
    "UserID::MovieID::Rating::Timestamp\n",
    "\n",
    "movies.dat's format is:  \n",
    "MovieID::Title::Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Collaborative filtering\n",
    "\n",
    "Collaborative filtering is commonly used for recommender systems. These techniques aim to fill in the missing entries of a user-item association matrix, in our case, the user-movie rating matrix. MLlib currently supports model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. In particular, we implement the alternating least squares (ALS) algorithm to learn these latent factors.\n",
    "\n",
    "---\n",
    "<img src=\"http://ampcamp.berkeley.edu/5/exercises/img/matrix_factorization.png\" height=\"300\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###User rating\n",
    "\n",
    "To create user rating you can use a python script called rateMovies. It ask you a raking for some movie and generate a file named personalRatings.txt.  \n",
    "You can launch python script in docker shell with fellowing command:  \n",
    "python rateMovies\n",
    "\n",
    "We have pregenerated this file for, if you want you can generate your personal rating file and use it in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Setup\n",
    "\n",
    "We start with import of libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "from os.path import join, isfile, dirname\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###User defined functions\n",
    "\n",
    "We define some functions to use after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseRating(line):\n",
    "    \"\"\"\n",
    "    Parses a rating record in MovieLens format userId::movieId::rating::timestamp .\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return long(fields[3]) % 10, (int(fields[0]), int(fields[1]), float(fields[2]))\n",
    "\n",
    "def parseMovie(line):\n",
    "    \"\"\"\n",
    "    Parses a movie record in MovieLens format movieId::movieTitle .\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return int(fields[0]), fields[1]\n",
    "\n",
    "def loadRatings(ratingsFile):\n",
    "    \"\"\"\n",
    "    Load ratings from file.\n",
    "    \"\"\"\n",
    "    if not isfile(ratingsFile):\n",
    "        print \"File %s does not exist.\" % ratingsFile\n",
    "        sys.exit(1)\n",
    "    f = open(ratingsFile, 'r')\n",
    "    ratings = filter(lambda r: r[2] > 0, [parseRating(line)[1] for line in f])\n",
    "    f.close()\n",
    "    if not ratings:\n",
    "        print \"No ratings provided.\"\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        return ratings\n",
    "\n",
    "def computeRmse(model, data, n):\n",
    "    \"\"\"\n",
    "    Compute RMSE (Root Mean Squared Error).\n",
    "    \"\"\"\n",
    "    predictions = model.predictAll(data.map(lambda x: (x[0], x[1])))\n",
    "    predictionsAndRatings = predictions.map(lambda x: ((x[0], x[1]), x[2])) \\\n",
    "      .join(data.map(lambda x: ((x[0], x[1]), x[2]))) \\\n",
    "      .values()\n",
    "    return sqrt(predictionsAndRatings.map(lambda x: (x[0] - x[1]) ** 2).reduce(add) / float(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load personal rating from local file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load personal ratings\n",
    "FILE_PATH = \"/notebooks/cineca/data/movielens/medium/\"\n",
    "myRatings = loadRatings(FILE_PATH + \"personalRatings.txt\")\n",
    "myRatingsRDD = sc.parallelize(myRatings, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset in hdfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: `/movielens': File exists\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -mkdir /movielens\n",
    "hdfs dfs -put /notebooks/cineca/data/movielens/medium/ratings.dat /movielens/ratings.dat\n",
    "hdfs dfs -put /notebooks/cineca/data/movielens/medium/movies.dat /movielens/movies.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ratings from hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))\n",
    "#ratings = sc.textFile(\"file://\" + FILE_PATH + \"ratings.dat\").map(parseRating)\n",
    "ratings = sc.textFile(\"/movielens/ratings.dat\").map(parseRating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load movie dataset from hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# movies is an RDD of (movieId, movieTitle)\n",
    "movies = dict(sc.textFile(\"/movielens/movies.dat\").map(parseMovie).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some operation on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1000209 ratings from 6040 users on 3706 movies.\n"
     ]
    }
   ],
   "source": [
    "numRatings = ratings.count()\n",
    "numUsers = ratings.values().map(lambda r: r[0]).distinct().count()\n",
    "numMovies = ratings.values().map(lambda r: r[1]).distinct().count()\n",
    "\n",
    "print \"Got %d ratings from %d users on %d movies.\" % (numRatings, numUsers, numMovies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Splitting training data\n",
    "\n",
    "We will use MLlibâ€™s ALS to train a MatrixFactorizationModel, which takes a RDD[Rating] object as input in Scala and RDD[(user, product, rating)] in Python. ALS has training parameters such as rank for matrix factors and regularization constants. To determine a good combination of the training parameters, we split the data into three non-overlapping subsets, named training, test, and validation, based on the last digit of the timestamp, and cache them. We will train multiple models based on the training set, select the best model on the validation set based on RMSE (Root Mean Squared Error), and finally evaluate the best model on the test set. We also add your ratings to the training set to make recommendations for you. We hold the training, validation, and test sets in memory by calling cache because we need to visit them multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 602252, validation: 198919, test: 199049\n"
     ]
    }
   ],
   "source": [
    "numPartitions = 4\n",
    "\n",
    "training = ratings.filter(lambda x: x[0] < 6).values().union(myRatingsRDD).repartition(numPartitions).cache()\n",
    "validation = ratings.filter(lambda x: x[0] >= 6 and x[0] < 8).values().repartition(numPartitions).cache()\n",
    "test = ratings.filter(lambda x: x[0] >= 8).values().cache()\n",
    "\n",
    "numTraining = training.count()\n",
    "numValidation = validation.count()\n",
    "numTest = test.count()\n",
    "\n",
    "print \"Training: %d, validation: %d, test: %d\" % (numTraining, numValidation, numTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Get the best model\n",
    "\n",
    "In this tutorial we try different combination of parameters (rank, lambda and number of iterations) to get the best model.  \n",
    "Parameters:  \n",
    "Ranks 8, 12  \n",
    "Lambdas 1, 10  \n",
    "Number of interations 10, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (validation) = 1.361322 for the model trained with rank = 8, lambda = 1.0, and numIter = 10.\n",
      "RMSE (validation) = 1.361321 for the model trained with rank = 8, lambda = 1.0, and numIter = 20.\n",
      "RMSE (validation) = 3.755870 for the model trained with rank = 8, lambda = 10.0, and numIter = 10.\n",
      "RMSE (validation) = 3.755870 for the model trained with rank = 8, lambda = 10.0, and numIter = 20.\n",
      "RMSE (validation) = 1.361321 for the model trained with rank = 12, lambda = 1.0, and numIter = 10.\n",
      "RMSE (validation) = 1.361321 for the model trained with rank = 12, lambda = 1.0, and numIter = 20.\n",
      "RMSE (validation) = 3.755870 for the model trained with rank = 12, lambda = 10.0, and numIter = 10.\n",
      "RMSE (validation) = 3.755870 for the model trained with rank = 12, lambda = 10.0, and numIter = 20.\n",
      "The best model was trained with rank = 8 and lambda = 1.0, and numIter = 20, and its RMSE on the test set is 1.357077.\n"
     ]
    }
   ],
   "source": [
    "ranks = [8, 12]\n",
    "lambdas = [1.0, 10.0]\n",
    "numIters = [10, 20]\n",
    "bestModel = None\n",
    "bestValidationRmse = float(\"inf\")\n",
    "bestRank = 0\n",
    "bestLambda = -1.0\n",
    "bestNumIter = -1\n",
    "\n",
    "for rank, lmbda, numIter in itertools.product(ranks, lambdas, numIters):\n",
    "    model = ALS.train(training, rank, numIter, lmbda)\n",
    "    validationRmse = computeRmse(model, validation, numValidation)\n",
    "    print \"RMSE (validation) = %f for the model trained with \" % validationRmse + \\\n",
    "          \"rank = %d, lambda = %.1f, and numIter = %d.\" % (rank, lmbda, numIter)\n",
    "    if (validationRmse < bestValidationRmse):\n",
    "        bestModel = model\n",
    "        bestValidationRmse = validationRmse\n",
    "        bestRank = rank\n",
    "        bestLambda = lmbda\n",
    "        bestNumIter = numIter\n",
    "\n",
    "testRmse = computeRmse(bestModel, test, numTest)\n",
    "\n",
    "# evaluate the best model on the test set\n",
    "print \"The best model was trained with rank = %d and lambda = %.1f, \" % (bestRank, bestLambda) \\\n",
    "  + \"and numIter = %d, and its RMSE on the test set is %f.\" % (bestNumIter, testRmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###How use learned model?\n",
    "\n",
    "Complete in the fellowing line istructions to suggest 50 film based on personal rating and the best learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies recommended for you:\n",
      " 1: I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      " 2: Time of the Gypsies (Dom za vesanje) (1989)\n",
      " 3: Smashing Time (1967)\n",
      " 4: Gate of Heavenly Peace, The (1995)\n",
      " 5: Follow the Bitch (1998)\n",
      " 6: Zachariah (1971)\n",
      " 7: Bewegte Mann, Der (1994)\n",
      " 8: Institute Benjamenta, or This Dream People Call Human Life (1995)\n",
      " 9: For All Mankind (1989)\n",
      "10: Hour of the Pig, The (1993)\n",
      "11: Man of the Century (1999)\n",
      "12: Lamerica (1994)\n",
      "13: Lured (1947)\n",
      "14: Apple, The (Sib) (1998)\n",
      "15: Sanjuro (1962)\n",
      "16: I Can't Sleep (J'ai pas sommeil) (1994)\n",
      "17: Bells, The (1926)\n",
      "18: Shawshank Redemption, The (1994)\n",
      "19: Collectionneuse, La (1967)\n",
      "20: Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "21: 24 7: Twenty Four Seven (1997)\n",
      "22: Usual Suspects, The (1995)\n",
      "23: Godfather, The (1972)\n",
      "24: Close Shave, A (1995)\n",
      "25: Big Trees, The (1952)\n",
      "26: Wrong Trousers, The (1993)\n",
      "27: Paths of Glory (1957)\n",
      "28: Soft Fruit (1999)\n",
      "29: Schindler's List (1993)\n",
      "30: Third Man, The (1949)\n",
      "31: Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)\n",
      "32: Raiders of the Lost Ark (1981)\n",
      "33: Rear Window (1954)\n",
      "34: Skipped Parts (2000)\n",
      "35: Celebration, The (Festen) (1998)\n",
      "36: Star Wars: Episode IV - A New Hope (1977)\n",
      "37: Double Indemnity (1944)\n",
      "38: Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)\n",
      "39: To Kill a Mockingbird (1962)\n",
      "40: Ballad of Narayama, The (Narayama Bushiko) (1982)\n",
      "41: Yojimbo (1961)\n",
      "42: Bridge on the River Kwai, The (1957)\n",
      "43: I, Worst of All (Yo, la peor de todas) (1990)\n",
      "44: Sixth Sense, The (1999)\n",
      "45: World of Apu, The (Apur Sansar) (1959)\n",
      "46: One Flew Over the Cuckoo's Nest (1975)\n",
      "47: Casablanca (1942)\n",
      "48: Grand Day Out, A (1992)\n",
      "49: Wallace & Gromit: The Best of Aardman Animation (1996)\n",
      "50: Strangers on a Train (1951)\n"
     ]
    }
   ],
   "source": [
    "# Get candidates (esclude from candidates movies already in rated in personal ratings)\n",
    "myRatedMovieIds = set([x[1] for x in myRatings])\n",
    "candidates = sc.parallelize(...)\n",
    "# To make prediction using the best model learned in the previous line\n",
    "predictions = ...\n",
    "# Get fist 50 from the list of predicted\n",
    "recommendations = ...\n",
    "\n",
    "print \"Movies recommended for you:\"\n",
    "for i in xrange(len(recommendations)):\n",
    "    print (\"%2d: %s\" % (i + 1, movies[recommendations[i][1]])).encode('ascii', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
